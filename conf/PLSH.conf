# for PLSH only

# IO
# HDFS output path
outputPath=/[SOME_PATH_ON_HDFS]
# item and query vector must be normalized! Its norm should be 1!
# The item/query vector must be sorted. { vid dim_1:val_1 dim_2:val_2 ... dim_n:val_n  }, dim_1 < dim_2 ... < dim_n.
itemPath=hdfs:///[SOME_PATH_ON_HDFS]
queryPath=hdfs:///[SOME_PATH_ON_HDFS]



# HOW DOES HASH FUNCTION WORK?
#
# Each hash function is a vector<float>, whose size is 'dimension'. And each of its dimension generated by:
# std::normal_distribution<float> distribution(0.0, 1.0);
#
# In PLSH, we will calculate the dot product between a hash function and a vector (they have same dimension).
# If the dot product >= 0, then we consider it as a '1'.
# If the dot product < 0, then we consider it as a '0'.
#
# 'row/2' hash functions consist of a hash function group, which generate half of the vector<bool> signature (consider each boolean as a bit).
# A hash function group generate a bit sequence of length 'row/2'. 
# To generate a full vector<bool> signature, whose length is 'row', we need two such hash function groups. 
#
# We have 'm' hash function groups in total. If we randomly pick two hash function groups, we can have m * (m-1) / 2 combinations.
# That's the total signatures number, as well as 'band'. band = m * (m-1) / 2.
#
# At last, we will convert the vector<bool> signature to a vector<int> signature. 
# Compress 32 bool as one int.
#
# The final result store in vector< vector<int> >, each inner vector<int> is a signature which corresponds to a bucket.



# App Parms
row=8               # Length of the bool vector signatures. 
band=3              # Number of hash function group combinations. band = m * (m-1) / 2.
dimension=5         # Dimension of each vector (query_vector, item_vector and hash function, which is also a vector)
seed=0              # Seed which is used to generate normal_distribution number.
iters=1
radians=0.9         # If two vector's radians is smaller than this, then they will be output.

# Cluster Configuration
master_host=localhost
master_port=13919
comm_port=13242

hdfs_namenode=localhost
hdfs_namenode_port=9000

serve=1

[worker]
info=localhost:1
#info=worker1:4
#info=worker2:4
